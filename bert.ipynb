{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from util import pre_process\n",
    "import pickle\n",
    "import torch\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda!\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../data_2020/'\n",
    "model_path = 'models/'\n",
    "other_path = 'others/'\n",
    "n = 3\n",
    "MAX_LEN = 512\n",
    "drop_no_content = True\n",
    "MIN_LEN = 7\n",
    "workers = mp.cpu_count()-2\n",
    "lr = 1e-5\n",
    "epochs = 3\n",
    "colsample_bytree = 0.8\n",
    "seed = 9487\n",
    "use_cuda = torch.cuda.is_available()\n",
    "no = \"2\"\n",
    "if use_cuda:\n",
    "    print(\"using cuda!\")\n",
    "device = torch.device(\"cuda:\"+no) if use_cuda else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prediction\n",
    "test = pd.read_csv(data_path+'validation.csv')\n",
    "# get meta\n",
    "train_data = pd.read_csv(data_path+'train_data_merge_bm25_tfidf_{}.csv'.format(n))\n",
    "test_data = pd.read_csv(data_path+'test_data_merge_bm25_tfidf_{}.csv'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = pd.read_csv(data_path+'candidate_paper_pre.csv'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4207084693919729"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((train_data['journal'] == 'no-content').values)/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0313082497181351"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((test_data['journal'] == 'no-content').values)/test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_tfidf[train_data.groupby('description_id')['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_data_tfidf=train_data.iloc[:528750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_data_tfidf[train_data_tfidf['label']==1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_tfidf[train_data_tfidf['label']!=1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class gelu(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(gelu, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        cdf = 0.5 * (1.0 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "        return x * cdf\n",
    "\n",
    "    \n",
    "class MutiLabelModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, emb_size=768, out_size=1): # hidden=256\n",
    "        super(MutiLabelModel, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.fn_size = emb_size\n",
    "\n",
    "#         self.out_fn = nn.Sequential(\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(self.fn_size, self.fn_size//2),\n",
    "#             gelu(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(self.fn_size//2,100),\n",
    "#         )\n",
    "#         self.cos = nn.CosineSimilarity()\n",
    "        self.out_fn=nn.Linear(self.fn_size*4, 1)\n",
    "        \n",
    "    def forward(self, inp1, seg_inp1,inp2, seg_inp2,cat_emb=None, cls_loc=0): # , inp_title, seg_inp_title, cls_loc=0):\n",
    "\n",
    "        # batch = 1\n",
    "        embs1 = self.encoder(inp1, token_type_ids=seg_inp1)[0] # [batch, seq, hidden]\n",
    "        outputs1 = embs1[:, cls_loc, :]\n",
    "#         outputs1 = self.out_fn(outputs1)\n",
    "        embs2 = self.encoder(inp2, token_type_ids=seg_inp2)[0] # [batch, seq, hidden]\n",
    "        outputs2 = embs2[:, cls_loc, :]\n",
    "#         outputs2 = self.out_fn(outputs2)\n",
    "        outputs=torch.cat([outputs1,outputs2,torch.abs(outputs1-outputs2),outputs1*outputs2],dim=1)\n",
    "#         outputs = self.cos(outputs1,outputs2)\n",
    "        outputs=self.out_fn(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading bert...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nloading bert...\")\n",
    "tokenizer = BertTokenizer.from_pretrained('scibert_scivocab_uncased')\n",
    "encoder = BertModel.from_pretrained('scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MutiLabelModel(encoder).to(device)\n",
    "model.load_state_dict(torch.load(model_path+\"model_9487\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thd=0.5\n",
    "# batch_size=8\n",
    "# result=[]\n",
    "# epochs=1\n",
    "# num_total_steps = np.ceil(train_data.shape[0] / batch_size)*epochs\n",
    "# num_warmup_steps = int(num_total_steps * 0.5)\n",
    "# model=model.to(device)\n",
    "# optim = AdamW(model.parameters(), lr=lr, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
    "# scheduler = WarmupLinearSchedule(optim, warmup_steps=num_warmup_steps, t_total=num_total_steps)\n",
    "# for ep in range(epochs):\n",
    "#     model = model.train()\n",
    "#     criterion = nn.BCEWithLogitsLoss()\n",
    "#     optim.zero_grad()\n",
    "#     total_loss = 0.0\n",
    "#     pbar =tqdm(enumerate(train_data[['description_text','title_pro','label']].values),total=train_data.shape[0])\n",
    "#     for sidx, r in pbar:\n",
    "#         if (sidx+1) % batch_size == 0:\n",
    "#             optim.step()\n",
    "#             scheduler.step()\n",
    "#             optim.zero_grad()\n",
    "#         input_ids1 = tokenizer.encode('[CLS] '+r[0]+' [SEP] ')[:MAX_LEN]\n",
    "#         input_ids2 = tokenizer.encode('[CLS] '+r[1]+' [SEP]')[:MAX_LEN]\n",
    "#         input_ids1 = torch.tensor([input_ids1]).long().to(device)\n",
    "#         input_ids2 = torch.tensor([input_ids2]).long().to(device)\n",
    "#         segments_ids1 = [ 0 for i in range(len(input_ids1)) ]\n",
    "#         segments_ids1 = torch.tensor([segments_ids1]).long().to(device)\n",
    "#         segments_ids2 = [ 0 for i in range(len(input_ids2)) ]\n",
    "#         segments_ids2 = torch.tensor([segments_ids2]).long().to(device)\n",
    "#         target = torch.FloatTensor([r[2]]).to(device).view(1,-1)\n",
    "#         out = model(input_ids1, segments_ids1,input_ids2, segments_ids2) \n",
    "#         l = criterion(out, target)\n",
    "#         total_loss += l.item()\n",
    "#         out = torch.sigmoid(out)\n",
    "#         pred = (out >thd)\n",
    "#         result.append((out.item(),pred.long().item(),r[2]))\n",
    "#         l.backward()\n",
    "#         if sidx!=0:\n",
    "#             pbar.set_postfix({\"loss: \": total_loss/sidx})\n",
    "#     optim.step()\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"model_{}\".format(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate_bertembed={}\n",
    "# for r in tqdm(candidate[['paper_id','title_pro']].values):\n",
    "#     input_ids1 = tokenizer.encode('[CLS] '+r[1]+' [SEP] ')[:MAX_LEN]\n",
    "#     input_ids1 = torch.tensor([input_ids1]).long().to(device)\n",
    "#     segments_ids1 = [ 0 for i in range(len(input_ids1)) ]\n",
    "#     segments_ids1 = torch.tensor([segments_ids1]).long().to(device)\n",
    "#     embs1 = model.encoder(input_ids1, token_type_ids=segments_ids1)[0] # [batch, seq, hidden]\n",
    "#     outputs1 = embs1[:, 0, :]\n",
    "#     candidate_bertembed[r[0]]=outputs1.cpu().detach().numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('candidate_bertembed.pickle', 'wb') as f:\n",
    "#     pickle.dump(candidate_bertembed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre = pd.read_csv(data_path+'test_pre.csv')\n",
    "# get meta\n",
    "train_pre = pd.read_csv(data_path+'train_pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2476608f2793499fb586e31c9de10ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=62974.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_pre_bertembed={}\n",
    "for r in tqdm(train_pre[['description_id','description_text_pre']].values):\n",
    "    input_ids1 = tokenizer.encode('[CLS] '+r[1]+' [SEP] ')[:MAX_LEN]\n",
    "    input_ids1 = torch.tensor([input_ids1]).long().to(device)\n",
    "    segments_ids1 = [ 0 for i in range(len(input_ids1)) ]\n",
    "    segments_ids1 = torch.tensor([segments_ids1]).long().to(device)\n",
    "    embs1 = model.encoder(input_ids1, token_type_ids=segments_ids1)[0] # [batch, seq, hidden]\n",
    "    outputs1 = embs1[:, 0, :]\n",
    "    train_pre_bertembed[r[0]]=outputs1.cpu().detach().numpy()\n",
    "# # with open('train_pre_bertembed.pickle', 'wb') as f:\n",
    "# #     pickle.dump(train_pre_bertembed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3241e425fbf645079a0ab2bfca9cdb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34428.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_pre_bertembed={}\n",
    "for r in tqdm(test_pre[['description_id','description_text_pre']].values):\n",
    "    input_ids1 = tokenizer.encode('[CLS] '+r[1]+' [SEP] ')[:MAX_LEN]\n",
    "    input_ids1 = torch.tensor([input_ids1]).long().to(device)\n",
    "    segments_ids1 = [ 0 for i in range(len(input_ids1)) ]\n",
    "    segments_ids1 = torch.tensor([segments_ids1]).long().to(device)\n",
    "    embs1 = model.encoder(input_ids1, token_type_ids=segments_ids1)[0] # [batch, seq, hidden]\n",
    "    outputs1 = embs1[:, 0, :]\n",
    "    test_pre_bertembed[r[0]]=outputs1.cpu().detach().numpy()\n",
    "# with open('test_pre_bertembed.pickle', 'wb') as f:\n",
    "#     pickle.dump(test_pre_bertembed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in list(test_pre_bertembed.keys()):\n",
    "    if type(k) == float:\n",
    "        test_pre_bertembed['none'] = test_pre_bertembed[k].copy()\n",
    "        print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03e965357fa4473ba28e653390cda22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=62973.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bda80dd4ff40d8a04fc388ab9dda42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34428.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "description2embedding = {}\n",
    "paper2embedding = {}\n",
    "\n",
    "for k in tqdm(list(train_pre_bertembed.keys())):\n",
    "    description2embedding[k+'_train'] = np.array(train_pre_bertembed[k][0])\n",
    "for k in tqdm(list(test_pre_bertembed.keys())):\n",
    "    description2embedding[str(k)+'_test'] = np.array(test_pre_bertembed[k][0])\n",
    "    \n",
    "# for k in tqdm(list(candidate_bertembed.keys())):\n",
    "#     paper2embedding[k] = np.array(candidate_bertembed[k][0])\n",
    "    \n",
    "# with open(other_path+'paper2embedding_pre.pkl', 'wb') as f:\n",
    "#     pickle.dump(paper2embedding, f)\n",
    "with open(other_path+'description2embedding_pre.pkl', 'wb') as f:\n",
    "    pickle.dump(description2embedding, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97401"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description2embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
